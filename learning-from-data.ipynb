{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning From Data\n",
    "\n",
    "## Chapter 1 - The Learning Problem\n",
    "\n",
    "### Main components of a Learning problem\n",
    "\n",
    "* The __input__ $x$\n",
    "* The unknown __target function__ $f : X \\to Y$\n",
    "* A __data set__ $D$ of input-output examples $(x_i, y_i)$\n",
    "* The __hypothesis set__ $H$ \n",
    "* The __learning algorithm__ (will chose the data set $D$ to pick a formula $g : X \\to Y$ that belongs to $H$ and approximates $f$)\n",
    "\n",
    "### The Perceptron Learning Algorithm\n",
    "\n",
    "Used to find a vector of weights $w$ to choose an hypothesis $h(x) = sign(w^T x)$ ($x$ being the input vector) when the data is linearly separable.\n",
    "\n",
    "At each iteration $t$ there's a current weight vector $w(t)$. The algorithm picks an example $(x(t), y(t))$ that is currently missclassified and uses it to update $w(t)$, the update rule is: $w(t+1) = w(t) + y(t)x(t)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Exercise 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is Learning Feasible?\n",
    "\n",
    "- Hoeffding Inequality: $$P[|v-\\mu| > \\epsilon] \\le 2e^{-2 \\epsilon^2 N}$$\n",
    "- In-sample error: $$E_{in}(h) = \\frac{1}{N} \\sum_{n=1}^N [[h(x_n) \\ne f(x_n)]]$$\n",
    "- Out-of-sample error: $$E_{out}(h) = P[h(x) \\ne f(x)]$$\n",
    "\n",
    "$$P[|E_{in}(h)-E_{out}(h)| > \\epsilon] \\le 2e^{-2 \\epsilon^2 N}$$\n",
    "\n",
    "- Since we visit $m$ hs to get to $g$:\n",
    "\n",
    "$$P[|E_{in}(g)-E_{out}(g)| > \\epsilon] \\le \\sum_{m=1}^M{P[|E_{in}(h_m) - E_{out}(h_m)| > \\epsilon]}$$\n",
    "\n",
    "$$P[|E_{in}(g)-E_{out}(g)| > \\epsilon] \\le 2Me^{-2\\epsilon^2N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO Exercise 1.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1\n",
    "\n",
    "- 3, 4, 5 ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy, random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOW = -1.0\n",
    "HIGH = 1.0\n",
    "TEST_SIZE = 1000\n",
    "\n",
    "def random_point():\n",
    "    return numpy.random.uniform(low=LOW, high=HIGH, size=2)\n",
    "\n",
    "def random_line():\n",
    "    p1 = random_point()\n",
    "    p2 = random_point()\n",
    "    m = (p2[1]-p1[1])/(p2[0]-p1[0])\n",
    "    b = p1[1] - m*p1[0]\n",
    "    return (m, b)\n",
    "\n",
    "def target_output(point, line):\n",
    "    return -1 if (point[1] < (line[0]*point[0])+line[1]) else 1\n",
    "    \n",
    "def hyp_output(point, wt):\n",
    "    res = sum(numpy.append(point, 1.0)*wt)\n",
    "    if res < 0:\n",
    "        return -1\n",
    "    elif res > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def wrong_points(sample, target_line, wt):\n",
    "    return [x for x in sample if target_output(x, target_line) != hyp_output(x, wt)]\n",
    "\n",
    "def run(size):\n",
    "    target_line = random_line()\n",
    "    sample = [random_point() for _ in range(size)]\n",
    "    wt = numpy.array([0, 0, 0])\n",
    "    t = 0\n",
    "    \n",
    "    while True:\n",
    "        misclassified = wrong_points(sample, target_line, wt)\n",
    "        if not len(misclassified):\n",
    "            break\n",
    "            \n",
    "        current = random.choice(misclassified)\n",
    "        wt = wt + numpy.append(current, 1.0)*target_output(current, target_line)\n",
    "        t += 1\n",
    "    \n",
    "    wrong_prob = len(wrong_points([random_point() for _ in range(TEST_SIZE)], target_line, wt))/TEST_SIZE\n",
    "    \n",
    "    return (wt, t, wrong_prob)\n",
    "        \n",
    "def runs(size):\n",
    "    results = [run(size) for _ in range(TEST_SIZE)]\n",
    "    return sum([numpy.array([x[1], x[2]]) for x in results])/TEST_SIZE\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.813   ,  0.106219])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00806000e+02,   1.36800000e-02])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
